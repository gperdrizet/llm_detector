{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalized classifier v2.0\n",
    "\n",
    "Now all that's left to be done is wire up some routing logic between the models so we can easily do inference on incoming text. Workflow will looks something like this:\n",
    "\n",
    "1. **Stage I features**: calculate perplexity ratio and TF-IDF based features for input text.\n",
    "2. **Stage I classifier**: send feature vector to correct stage I classifiers based on text length.\n",
    "3. **Stage II features**: create new feature vector for with stage I class probabilities, perplexity ration and TF-IDF features.\n",
    "4. **Stage II classifier**: send new feature vector to correct stage II classifier for final prediction.\n",
    "\n",
    "Each step requires assets from the feature engineering and classifier training phases. Let's make a checklist to help make sure we have everything in place.\n",
    "\n",
    "1. **Stage I features**:\n",
    "    - Perplexity ratio score: tokenizer + reader and writer models.\n",
    "    - Perplexity ratio Kullback-Leibler score: perplexity ratio Kullback-Leibler divergence kernel density estimate for each bin.\n",
    "    - TF-IDF score: human and synthetic TF-IDF look-up tables for each bin.\n",
    "    - TF-IDF Kullback-Leibler score: TF-IDF Kullback-Leibler divergence kernel density estimate for each bin.\n",
    "\n",
    "2. **Stage I classifier**:\n",
    "    - Trained XGBoost classifier model for each bin.\n",
    "\n",
    "3. **Stage II features**\n",
    "    - Perplexity ratio Kullback-Leibler score: perplexity ratio Kullback-Leibler divergence kernel density estimate for each bin.\n",
    "    - TF-IDF score: human and synthetic TF-IDF look-up tables for each bin.\n",
    "    - TF-IDF Kullback-Leibler score: TF-IDF Kullback-Leibler divergence kernel density estimate for each bin.\n",
    "\n",
    "4. **Stage II classifier**\n",
    "    - Trained XGBoost classifier model for each bin.\n",
    "\n",
    "## 1. Run setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /mnt/arkk/llm_detector/classifier\n"
     ]
    }
   ],
   "source": [
    "# Change working directory to parent so we can import as we would from main.py\n",
    "print(f'Working directory: ', end = '')\n",
    "%cd ..\n",
    "\n",
    "# PyPI imports\n",
    "import h5py\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Internal imports\n",
    "import configuration as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the stage I training data and take just the text and labels. We will be treating each fragment as if it we submitted by a user and therefore all we will have is the text string. We will use the labels later to check the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 39042 training text fragments\n",
      "Have 39042 training text fragment labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fragment length (words)</th>\n",
       "      <th>Fragment length (tokens)</th>\n",
       "      <th>Source</th>\n",
       "      <th>String</th>\n",
       "      <th>Perplexity</th>\n",
       "      <th>Cross-perplexity</th>\n",
       "      <th>Perplexity ratio score</th>\n",
       "      <th>Perplexity ratio score Kullback-Leibler divergence</th>\n",
       "      <th>Human TF-IDF</th>\n",
       "      <th>Synthetic TF-IDF</th>\n",
       "      <th>TF-IDF score</th>\n",
       "      <th>TF-IDF score Kullback-Leibler divergence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>human</td>\n",
       "      <td>It’s a disease people just don’t know about. T...</td>\n",
       "      <td>3.127</td>\n",
       "      <td>2.832031</td>\n",
       "      <td>1.104138</td>\n",
       "      <td>0.473190</td>\n",
       "      <td>-3.385168</td>\n",
       "      <td>-3.422211</td>\n",
       "      <td>-0.252168</td>\n",
       "      <td>0.071449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>45</td>\n",
       "      <td>human</td>\n",
       "      <td>Owens(c) vs Roman Reigns – WWE Universal Champ...</td>\n",
       "      <td>2.912</td>\n",
       "      <td>3.027344</td>\n",
       "      <td>0.961935</td>\n",
       "      <td>0.120746</td>\n",
       "      <td>-2.634773</td>\n",
       "      <td>-2.650256</td>\n",
       "      <td>-0.081826</td>\n",
       "      <td>0.067688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>371</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>chemical or pharmaceutical processes.\\nhowever...</td>\n",
       "      <td>2.193</td>\n",
       "      <td>2.675781</td>\n",
       "      <td>0.819708</td>\n",
       "      <td>3.325138</td>\n",
       "      <td>-2.862300</td>\n",
       "      <td>-2.877875</td>\n",
       "      <td>-0.089403</td>\n",
       "      <td>0.067875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>human</td>\n",
       "      <td>unstable area near the Iraq and Syria border. ...</td>\n",
       "      <td>2.730</td>\n",
       "      <td>2.695312</td>\n",
       "      <td>1.013043</td>\n",
       "      <td>0.203559</td>\n",
       "      <td>-3.475644</td>\n",
       "      <td>-3.331192</td>\n",
       "      <td>0.983256</td>\n",
       "      <td>0.037913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>ins , is encoded by a gene family with at leas...</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.693359</td>\n",
       "      <td>0.819143</td>\n",
       "      <td>3.306112</td>\n",
       "      <td>-2.650665</td>\n",
       "      <td>-2.901612</td>\n",
       "      <td>-1.393327</td>\n",
       "      <td>0.069538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fragment length (words)  Fragment length (tokens)     Source  \\\n",
       "0                       32                        46      human   \n",
       "1                       27                        45      human   \n",
       "2                      268                       371  synthetic   \n",
       "3                      112                       131      human   \n",
       "4                       32                        44  synthetic   \n",
       "\n",
       "                                              String  Perplexity  \\\n",
       "0  It’s a disease people just don’t know about. T...       3.127   \n",
       "1  Owens(c) vs Roman Reigns – WWE Universal Champ...       2.912   \n",
       "2  chemical or pharmaceutical processes.\\nhowever...       2.193   \n",
       "3  unstable area near the Iraq and Syria border. ...       2.730   \n",
       "4  ins , is encoded by a gene family with at leas...       3.025   \n",
       "\n",
       "   Cross-perplexity  Perplexity ratio score  \\\n",
       "0          2.832031                1.104138   \n",
       "1          3.027344                0.961935   \n",
       "2          2.675781                0.819708   \n",
       "3          2.695312                1.013043   \n",
       "4          3.693359                0.819143   \n",
       "\n",
       "   Perplexity ratio score Kullback-Leibler divergence  Human TF-IDF  \\\n",
       "0                                           0.473190      -3.385168   \n",
       "1                                           0.120746      -2.634773   \n",
       "2                                           3.325138      -2.862300   \n",
       "3                                           0.203559      -3.475644   \n",
       "4                                           3.306112      -2.650665   \n",
       "\n",
       "   Synthetic TF-IDF  TF-IDF score  TF-IDF score Kullback-Leibler divergence  \n",
       "0         -3.422211     -0.252168                                  0.071449  \n",
       "1         -2.650256     -0.081826                                  0.067688  \n",
       "2         -2.877875     -0.089403                                  0.067875  \n",
       "3         -3.331192      0.983256                                  0.037913  \n",
       "4         -2.901612     -1.393327                                  0.069538  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the stage I training data and take just the text and labels\n",
    "\n",
    "# Stage I dataset\n",
    "dataset_name='falcon-7b_scores_v2_10-300_words_stage_I'\n",
    "\n",
    "# Input file path\n",
    "input_file=f'{config.DATA_PATH}/{dataset_name}.h5'\n",
    "\n",
    "# Open the new hdf5 file with pandas so we can work with dataframes\n",
    "data_lake=pd.HDFStore(input_file)\n",
    "\n",
    "# Get the features and extract just the text\n",
    "training_df=data_lake['training/combined/features']\n",
    "texts=training_df['String'].to_list()\n",
    "print(f'Have {len(texts)} training text fragments')\n",
    "\n",
    "# Get the corresponding labels\n",
    "labels=data_lake['training/combined/labels'].to_list()\n",
    "print(f'Have {len(labels)} training text fragment labels')\n",
    "\n",
    "# Close the connection to the hdf5 file\n",
    "data_lake.close()\n",
    "\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
